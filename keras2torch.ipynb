{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define constants for input sequence lengths (thresholds)\n",
    "BACTERIUM_THRESHOLD = 7000000  # length for padded bacterium sequence\n",
    "PHAGE_THRESHOLD = 200000      # length for padded phage sequence\n",
    "\n",
    "class BacteriaBranch(nn.Module):\n",
    "    \"\"\"CNN branch for bacterial DNA sequence.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(BacteriaBranch, self).__init__()\n",
    "        # Three convolutional layers with specified filters, kernel sizes, and strides\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=64, kernel_size=30, stride=10, bias=True)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=15, stride=5)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=25, stride=10, bias=True)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=10, stride=5)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=10, stride=5, bias=True)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Expect x shape: (batch, 4, BACTERIUM_THRESHOLD)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        # Flatten features\n",
    "        x = x.view(x.size(0), -1)  # flatten to (batch, features)\n",
    "        return x\n",
    "\n",
    "class PhageBranch(nn.Module):\n",
    "    \"\"\"CNN branch for phage DNA sequence.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(PhageBranch, self).__init__()\n",
    "        # Two convolutional layers for the phage branch\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=64, kernel_size=30, stride=10, bias=True)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=15, stride=5)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=25, stride=10, bias=True)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Expect x shape: (batch, 4, PHAGE_THRESHOLD)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class PerphectInteractionModel(nn.Module):\n",
    "    \"\"\"Dual-input CNN model for phage-bacteria interaction prediction.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(PerphectInteractionModel, self).__init__()\n",
    "        self.bacteria_branch = BacteriaBranch()\n",
    "        self.phage_branch = PhageBranch()\n",
    "        # After flattening, expected concatenated feature length = 15296 (8928 + 6368)\n",
    "        # This is computed from the convolution/pooling sequence given the input lengths\n",
    "        self.fc1 = nn.Linear(in_features=15296, out_features=100, bias=True)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=1, bias=True)\n",
    "        # Sigmoid will be applied in forward for binary classification output\n",
    "    \n",
    "    def forward(self, x_bacteria, x_phage):\n",
    "        # Permute inputs if they are (batch, length, channels) to (batch, channels, length)\n",
    "        if x_bacteria.dim() == 3 and x_bacteria.size(1) != 4:\n",
    "            x_bacteria = x_bacteria.permute(0, 2, 1)\n",
    "        if x_phage.dim() == 3 and x_phage.size(1) != 4:\n",
    "            x_phage = x_phage.permute(0, 2, 1)\n",
    "        # Pass through each branch\n",
    "        feat_bact = self.bacteria_branch(x_bacteria)\n",
    "        feat_phage = self.phage_branch(x_phage)\n",
    "        # Concatenate features from both branches\n",
    "        combined_feat = torch.cat([feat_bact, feat_phage], dim=1)\n",
    "        # Fully connected layers for prediction\n",
    "        x = F.relu(self.fc1(combined_feat))\n",
    "        x = self.dropout(x)\n",
    "        out = torch.sigmoid(self.fc2(x))  # sigmoid for binary interaction probability\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h5py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'h5py'"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_keras_weights_to_pytorch(pytorch_model, keras_h5_path):\n",
    "    \"\"\"\n",
    "    Load weights from a Keras .h5 model file into a PyTorch model.\n",
    "    Assumes `pytorch_model` has the same architecture as the Keras model.\n",
    "    \"\"\"\n",
    "    # Open the Keras weights file\n",
    "    with h5py.File(keras_h5_path, 'r') as f:\n",
    "        # Access the 'model_weights' subgroup\n",
    "        model_weights = f['model_weights']\n",
    "\n",
    "        state_dict = {}  # will populate with parameter tensors\n",
    "\n",
    "        # Helper to load conv weights: transpose kernel to PyTorch format\n",
    "        def copy_conv(layer_name, pytorch_weight_key, pytorch_bias_key):\n",
    "            keras_kernel = model_weights[layer_name][layer_name]['kernel:0'][()]\n",
    "            keras_bias = model_weights[layer_name][layer_name]['bias:0'][()]\n",
    "            # Convert to PyTorch tensor and permute dimensions for kernel\n",
    "            state_dict[pytorch_weight_key] = torch.tensor(keras_kernel).permute(2, 1, 0)\n",
    "            state_dict[pytorch_bias_key] = torch.tensor(keras_bias)\n",
    "\n",
    "        # Bacterial branch conv layers\n",
    "        copy_conv('bacterial_conv_1', 'bacteria_branch.conv1.weight', 'bacteria_branch.conv1.bias')\n",
    "        copy_conv('bacterial_conv_2', 'bacteria_branch.conv2.weight', 'bacteria_branch.conv2.bias')\n",
    "        copy_conv('bacterial_conv_3', 'bacteria_branch.conv3.weight', 'bacteria_branch.conv3.bias')\n",
    "        # Phage branch conv layers\n",
    "        copy_conv('phage_conv_1', 'phage_branch.conv1.weight', 'phage_branch.conv1.bias')\n",
    "        copy_conv('phage_conv_2', 'phage_branch.conv2.weight', 'phage_branch.conv2.bias')\n",
    "\n",
    "        # Dense layers (fully connected)\n",
    "        # Keras layer names are 'dense' for the first Dense(100) and 'dense_1' for the final Dense(1)\n",
    "        dense_kernel = model_weights['dense']['dense']['kernel:0'][()]   # shape (15296, 100)\n",
    "        dense_bias   = model_weights['dense']['dense']['bias:0'][()]     # shape (100,)\n",
    "        dense1_kernel = model_weights['dense_1']['dense_1']['kernel:0'][()]  # shape (100, 1)\n",
    "        dense1_bias   = model_weights['dense_1']['dense_1']['bias:0'][()]    # shape (1,)\n",
    "        # Transpose dense weight matrices for PyTorch and copy biases\n",
    "        state_dict['fc1.weight'] = torch.tensor(dense_kernel).t()\n",
    "        state_dict['fc1.bias']   = torch.tensor(dense_bias)\n",
    "        state_dict['fc2.weight'] = torch.tensor(dense1_kernel).t()\n",
    "        state_dict['fc2.bias']   = torch.tensor(dense1_bias)\n",
    "\n",
    "    # Load state_dict into the PyTorch model\n",
    "    pytorch_model.load_state_dict(state_dict)\n",
    "    return pytorch_model\n",
    "\n",
    "# Example usage:\n",
    "# model = PerphectInteractionModel()\n",
    "# model = load_keras_weights_to_pytorch(model, \"model_v1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    \"\"\"Grad-CAM for dual-branch 1D CNN model (phage-bacteria interaction).\"\"\"\n",
    "    def __init__(self, model, target_layer_bacteria=None, target_layer_phage=None):\n",
    "        self.model = model.eval()  # put model in evaluation mode\n",
    "        # Identify target layers (last conv layers in each branch)\n",
    "        if target_layer_bacteria is None:\n",
    "            target_layer_bacteria = model.bacteria_branch.conv3\n",
    "        if target_layer_phage is None:\n",
    "            target_layer_phage = model.phage_branch.conv2\n",
    "        self.target_layer_bacteria = target_layer_bacteria\n",
    "        self.target_layer_phage = target_layer_phage\n",
    "\n",
    "        # Placeholders for features and gradients\n",
    "        self.bact_features = None\n",
    "        self.phage_features = None\n",
    "\n",
    "        # Forward hooks to capture feature maps\n",
    "        target_layer_bacteria.register_forward_hook(self._save_bact_feature)\n",
    "        target_layer_phage.register_forward_hook(self._save_phage_feature)\n",
    "        # We will use .retain_grad() on feature maps to get gradients during backward\n",
    "\n",
    "    def _save_bact_feature(self, module, input, output):\n",
    "        \"\"\"Forward hook: store bacterial conv feature map and enable gradient retention.\"\"\"\n",
    "        self.bact_features = output  # feature map from conv3\n",
    "        output.retain_grad()        # keep gradient for this tensor\n",
    "\n",
    "    def _save_phage_feature(self, module, input, output):\n",
    "        \"\"\"Forward hook: store phage conv feature map and enable gradient retention.\"\"\"\n",
    "        self.phage_features = output  # feature map from conv2\n",
    "        output.retain_grad()\n",
    "\n",
    "    def generate(self, bact_input, phage_input):\n",
    "        \"\"\"\n",
    "        Compute Grad-CAM heatmaps for the given inputs.\n",
    "        Inputs should be tensors (1 x 4 x length) for each branch.\n",
    "        Returns:\n",
    "            cam_bact (numpy 1D array of length ~279) – importance map for bacterium sequence.\n",
    "            cam_phage (numpy 1D array of length ~199) – importance map for phage sequence.\n",
    "        \"\"\"\n",
    "        # Ensure model is in eval and gradients are zeroed\n",
    "        self.model.eval()\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        # Forward pass through the model\n",
    "        output = self.model(bact_input, phage_input)\n",
    "        # We assume a single input (batch size 1). If batch>1, pick the first instance or specify index.\n",
    "        target_score = output.squeeze()  # scalar prediction for interaction probability\n",
    "        # Backward pass to compute gradients of target_score w.r.t. feature maps\n",
    "        target_score.backward()\n",
    "\n",
    "        # Get the gradients of the conv feature maps\n",
    "        grad_bact = self.bact_features.grad  # shape: (1, channels, L_bact_feature)\n",
    "        grad_phage = self.phage_features.grad  # shape: (1, channels, L_phage_feature)\n",
    "\n",
    "        # Compute channel-wise weights: global average pooling of gradients over the length dimension\n",
    "        # This yields a weight for each channel (filter) of the conv layer\n",
    "        weights_bact = grad_bact.mean(dim=2, keepdim=True)  # shape: (1, channels, 1)\n",
    "        weights_phage = grad_phage.mean(dim=2, keepdim=True)\n",
    "\n",
    "        # Weight the feature maps by these importance weights and sum over channels\n",
    "        cam_bact = (weights_bact * self.bact_features).sum(dim=1)  # shape: (1, L_bact_feature)\n",
    "        cam_phage = (weights_phage * self.phage_features).sum(dim=1)  # shape: (1, L_phage_feature)\n",
    "\n",
    "        # Apply ReLU to the weighted maps to keep only positive contributions\n",
    "        cam_bact = F.relu(cam_bact)\n",
    "        cam_phage = F.relu(cam_phage)\n",
    "\n",
    "        # Remove batch dimension and normalize the heatmaps to [0, 1]\n",
    "        cam_bact = cam_bact.detach().cpu().numpy()[0]  # shape (L_bact_feature,)\n",
    "        cam_phage = cam_phage.detach().cpu().numpy()[0]\n",
    "        if cam_bact.max() != 0:\n",
    "            cam_bact = cam_bact / cam_bact.max()\n",
    "        if cam_phage.max() != 0:\n",
    "            cam_phage = cam_phage / cam_phage.max()\n",
    "\n",
    "        return cam_bact, cam_phage\n",
    "\n",
    "# Example usage:\n",
    "# gradcam = GradCAM(model)\n",
    "# cam_bact, cam_phage = gradcam.generate(bact_tensor, phage_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sequence_gradcam(sequence, importance_scores, start=None, end=None, window=100, cmap='coolwarm'):\n",
    "    \"\"\"\n",
    "    Plot a segment of the sequence with Grad-CAM importance scores overlaid as a heatmap.\n",
    "    - sequence: DNA sequence string (e.g., \"ACGT...\") \n",
    "    - importance_scores: 1D numpy array of Grad-CAM scores (normalized 0 to 1) corresponding to sequence positions.\n",
    "    - start, end: optional indices to specify the sequence region to plot. If None, will focus on top scoring region.\n",
    "    - window: if start/end not provided, the number of bases around the top score to display.\n",
    "    - cmap: colormap for the heatmap (default 'coolwarm').\n",
    "    \"\"\"\n",
    "    seq_len = len(sequence)\n",
    "    # Determine region to visualize\n",
    "    if start is None or end is None:\n",
    "        # Find the position of maximum importance and center the window around it\n",
    "        max_idx = int(np.argmax(importance_scores))\n",
    "        half_win = window // 2\n",
    "        start = max(0, max_idx - half_win)\n",
    "        end = min(seq_len, max_idx + half_win)\n",
    "    # Extract the region of interest\n",
    "    seq_region = sequence[start:end]\n",
    "    scores_region = importance_scores[start:end]\n",
    "\n",
    "    # Create heatmap image (1 x region_length) using importance scores\n",
    "    fig, ax = plt.subplots(figsize=(max(10, 0.2 * len(seq_region)), 2))\n",
    "    # Reshape scores to (1, L) for imshow\n",
    "    heatmap = scores_region[np.newaxis, :]  # shape (1, L_region)\n",
    "    im = ax.imshow(heatmap, aspect='auto', cmap=cmap, vmin=0, vmax=1)\n",
    "    # Set nucleotide labels on the x-axis\n",
    "    ax.set_xticks(np.arange(len(seq_region)))\n",
    "    ax.set_xticklabels(list(seq_region))\n",
    "    ax.set_yticks([])  # hide y-axis\n",
    "    ax.set_xlabel(f\"Sequence positions {start} to {end-1}\")\n",
    "    # Rotate labels if the region is long for better visibility\n",
    "    if len(seq_region) > 20:\n",
    "        plt.setp(ax.get_xticklabels(), rotation=90, fontsize=8)\n",
    "    # Add a color bar to show the importance scale\n",
    "    plt.colorbar(im, ax=ax, fraction=0.015, pad=0.1, label='Grad-CAM importance')\n",
    "    plt.title(\"Grad-CAM highlight on sequence segment\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "# Example usage (after obtaining cam_bact and cam_phage from GradCAM):\n",
    "# original_bact_seq = \"ACGTTG... (length 7000000, including 'Z' for padding)\" \n",
    "# fig, ax = plot_sequence_gradcam(original_bact_seq, cam_bact, window=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
